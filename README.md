# 🎮 스팀 리뷰 감성 분석 대시보드

이 프로젝트는 스팀(Steam) 게임 리뷰 데이터를 수집하고, 감성 분석 모델을 구축 및 평가하며, 그 결과를 시각화하는 전 과정을 지원하는 Streamlit 기반의 올인원 대시보드입니다.

## ✨ 주요 기능

-   **📥 데이터 수집**: App ID를 기반으로 특정 스팀 게임의 리뷰를 실시간으로 수집하고 CSV로 저장합니다.
![image](https://github.com/user-attachments/assets/3430a992-d27a-45a0-95bc-234415301329)<br>
:point_up:데이터 수집 과정<br>
![image](https://github.com/user-attachments/assets/0a940577-26dc-460a-b2e2-4b5c8f0678d0)<br>
:point_up:기존에 수집한 데이터 확인 가능<br>
<hr>

-   **🤖 LLM 기반 레이블링**: 로컬 LLM(LM Studio 등)을 활용하여 수집된 리뷰에 '긍정', '부정', '중립' 감성 레이블을 자동으로 부여합니다.
![image](https://github.com/user-attachments/assets/906ae66e-6049-42d3-a0fa-1749cc1380c1)<br>
:point_up:레이블링 전 데이터 개수, 미리보기, 컬럼 값 확인 가능<br>
![image](https://github.com/user-attachments/assets/191cb84d-2b6b-41e3-85a1-8ca30638f222)<br>
:point_up:레이블링 설정 후 실행<br>
<hr>

-   **🏋️ 듀얼 모델 학습**: 두 가지 종류의 모델을 학습시킬 수 있습니다.
    -   **Scikit-learn (로지스틱 회귀)**: 빠르고 안정적인 전통적 머신러닝 모델.
    -   **Deep Learning (LSTM)**: 더 높은 성능을 기대할 수 있는 딥러닝 모델.
![image](https://github.com/user-attachments/assets/4bb57d58-99d4-4cb8-9353-08415cdb3259)<br>
<hr>

-   **🧪 상세 모델 테스트**: 학습된 모델의 성능을 두 가지 방식으로 검증합니다.
    -   **파일 전체 테스트**: 테스트용 CSV 파일 전체에 대한 성능을 `Classification Report`와 `Confusion Matrix`로 상세히 분석합니다.
    -   **실시간 텍스트 판별**: 텍스트를 직접 입력하여 모델의 판별 결과를 즉시 확인하고, LLM의 결과와 나란히 비교할 수 있습니다.
![image](https://github.com/user-attachments/assets/b9cb16fb-6cb3-435d-932c-64e2a3bce26c)<br>
![image](https://github.com/user-attachments/assets/3ca716fe-1463-44d3-92a3-3bb985ac0d93)
:point_up:새로운 모델 생성 및 적은 데이터로 학습 시 낮은 정확도가 나올 수 있다.
<hr>

-   **🔄 피드백 루프 및 즉시 재학습**:
    -   실시간 판별 결과를 사용자가 직접 수정하여 피드백 데이터(`feedback_labeled_data.csv`)로 저장할 수 있습니다.
    -   Scikit-learn 모델의 경우, 피드백을 반영하여 **선택된 모델을 즉시 재학습**하고 덮어쓸 수 있습니다.
![image](https://github.com/user-attachments/assets/515b919e-2ad1-4f99-b7eb-acfd97f68843)<br>
:point_up:Scikit-learn은 즉시 피드백 추가<br>
<hr>

-   **📊 시각화**:
    -   분석 결과의 감성 분포를 파이 차트로 시각화합니다.
    -   '긍정', '부정', '중립' 각 레이블에 대한 워드 클라우드를 생성하여 핵심 키워드를 파악합니다.
![image](https://github.com/user-attachments/assets/3d76aeae-438c-4b27-805f-fc1943f95261)<br>
![image](https://github.com/user-attachments/assets/16773792-ee30-4d39-84c4-5ae506480c17)<br>
:point_up:기본 불용어 확인과 게임별, 임시 불용어 등록 가능<br>
![image](https://github.com/user-attachments/assets/e128024e-7dec-4b1f-9b4d-79323b88f4d0)<br>
<hr>

-   **⚙️ 3단계 불용어 관리**:
    -   **기본 불용어**: 모든 분석에 공통으로 적용되는 불용어를 UI에서 직접 관리 (`default_stop_words.json`).
    -   **게임별 불용어**: 특정 게임에만 적용되는 불용어를 별도로 관리 (`stopwords/[AppID].json`).
![image](https://github.com/user-attachments/assets/61230dd1-5853-4da5-ac6e-bb460a46eedd)<br>
:point_up:시각화에서 저장한 게임별 불용어 확인 가능<br>
<hr>

## 📁 프로젝트 구조

```text
.
├── app.py                   # 메인 Streamlit 애플리케이션
├── myLangchainService.py    # LLM 연동 서비스
├── requirements.txt         # 프로젝트 의존성 라이브러리
├── default_stop_words.json  # 기본 불용어 목록
├── data/                    # 데이터 저장 폴더 (CSV)
├── models/                  # 학습된 모델 저장 폴더
├── stopwords/               # 게임별 불용어 저장 폴더
├── result/                  # 테스트 결과 저장 폴더
├── lib/                     # 핵심 로직 모듈 폴더
│   ├── steam_api.py
│   ├── data_preprocessor.py
│   ├── model_trainer.py
│   ├── keras_model_manager.py
│   └── model_tester.py
└── pages/                   # 기능별 페이지 폴더
    ├── 1_데이터 수집.py
    ├── 2_LLM 라벨링.py
    ├── 3_모델 학습 및 테스트.py
    ├── 4_시각화.py
    └── 5_불용어 관리.py
```

## 📖 사용 방법 (추천 워크플로우)

1.  **[데이터 수집]** 페이지에서 분석하고 싶은 게임의 App ID를 입력하여 리뷰를 수집합니다.
2.  **[LLM 레이블링]** 페이지에서 방금 수집한 `steam_reviews_*.csv` 파일을 선택하여 감성 레이블을 자동으로 생성하고, `labeled_*.csv` 파일로 저장합니다.
3.  **[불용어 관리]** 페이지에서 분석에 방해가 될 만한 공통 단어들을 '기본 불용어'에 추가하고 저장합니다.
4.  **[모델 학습]** 페이지에서 다음을 수행합니다.
    -   학습할 모델 종류(Scikit-learn 또는 LSTM)를 선택합니다.
    -   레이블링된 `labeled_*.csv` 파일(들)을 선택합니다.
    -   '데이터 분포 확인'을 통해 데이터 상태를 점검합니다.
    -   '데이터 불균형 보정' 옵션을 체크하고 '학습 시작' 버튼을 눌러 모델을 생성하고 저장합니다.
5.  **[모델 테스트]** 페이지에서 다음을 수행합니다.
    -   **파일로 전체 테스트**: 방금 학습한 모델과 `labeled_*.csv` 파일을 선택하여 모델의 전반적인 성능(정확도, f1-score 등)을 확인합니다.
    -   **텍스트 직접 입력 테스트**: 모델을 선택하고, 특정 리뷰 문장을 입력하여 예측 결과를 확인합니다. LLM 결과와 비교하며 모델의 강점과 약점을 파악합니다.
6.  **(반복) '텍스트 직접 입력 테스트'** 에서 모델이 잘못 예측한 경우, **피드백 기능**을 사용하여 올바른 레이블과 함께 데이터를 저장합니다.
    -   **Scikit-learn 모델**의 경우, '즉시 재학습' 버튼으로 모델을 바로 업데이트할 수 있습니다.
    -   **LSTM 모델**의 경우, `feedback_labeled_data.csv`가 생성되므로, 4번 단계로 돌아가 이 파일을 학습 데이터에 포함하여 더 똑똑한 'v2' 모델을 만듭니다.
7.  **[시각화]** 페이지에서 최종적으로 완성된 모델과 데이터를 선택하여, 전체적인 감성 분포와 긍정/부정/중립 리뷰의 핵심 키워드를 워드클라우드로 확인합니다. 이때 '게임별 불용어'나 '임시 불용어'를 추가하여 분석의 질을 높일 수 있습니다.


## 🚀 구현 방식 및 시행착오

### 1. 데이터 수집
- **1차 구현**  
  Selenium 웹 스크레이핑 라이브러리를 사용하여 스팀 상점 페이지의 리뷰를 직접 수집
- **시행착오**  
    초기 Web Scraping 방식으로 웹브라우저를 제어하여 수집하였으나 1. 불필요한 데이터가 섞이거나 텍스트가 깨지는 문제, 2. 한글 필터가 제대로 작동하지 않는 문제, 3. 스크롤 동작에 따른 다음 리뷰 로딩이 늦어져 수집이 조기 종료되는 현상 발생
- **2차 구현(개선)**  
    1차 구현에서 수정 1. 리뷰 작성일자(Posted: [월 일 년]), EARLY ACCESS 리뷰에 붙는 텍스트 등을 필터링하여 저장 2. 한글이 들어가지 않은 리뷰 필터링 3. time.sleep과 5번 스크롤 이후에도 데이터 변화가 없다면 종료하는 코드 추가
- **3차 구현(개선)**  
    데이터 수집 속도에 문제가 있어 방법을 물색하다 스팀에서 제공하는 api 사용하여 수집하는 방식으로 변경
   
### 2. LLM 라벨링
- **1차 구현**  
    수집된 원본 CSV 파일을 ChatGPT에 직접 업로드하여 감성 레이블링을 요청하는 방식을 시도
- **시행착오**  
    ChatGPT의 토큰 입력 제한으로 인해 대용량 CSV 파일 처리가 불가능한 문제
    파일의 일부만 인식하여, 마치 Pandas의 .head() 함수로 상위 몇 개 행만 본 것처럼 처음 10개 정도의 행만 올바르게 처리하고 나머지는 누락시키는 문제
    10,000개의 데이터 중 처음 10개 행만 정상적으로 레이블링하고, 나머지 9,990개의 데이터는 모두 마지막 레이블 값('부정' 등)으로 덮어쓰거나 10개의 데이터를 그대로 10000개로 늘려버리는 등 신뢰할 수 없는 결과를 반환하는 문제
- **2차 구현(LLM 도입)**  
    LM Studio를 사용하여 로컬 환경에 Gemma3 모델을 직접 구동하고 API를 통해 데이터를 처리하는 방식으로 변경
- **시행착오**
    프롬프트에서 '긍정', '중립', '부정' 세 가지로만 답변하도록 엄격히 지시했음에도 불구하고, '긍정 부정', '긍정 긍정', '긍정 부정 긍정 부정' 등 때때로 지시를 벗어나는 비정형적인 답변을 생성
- **3차 구현(후처리 강화)**
    LLM의 예측 자체를 완벽하게 제어하는게 아닌 생성된 결과를 전처리 과정에서 '긍정', '중립', '부정' 데이터만 받아서 처리하는 방향으로 수정

### 3. 모델 학습 및 성능 검증
- **1차 구현**  
    초기 모델은 딥러닝 기반의 LSTM
    학습된 모델을 저장하고 저장된 모델을 불러와 추가 학습 혹은 성능 검증하는 기능
    약 2만개의 데이터로 초기 모델 학습
- **시행착오**  
    학습 실행 시 앞서 기술한 비정상 레이블링 문제로 The least populated class in y has only 1 member... 오류가 발생하며 중단
    전처리 과정에서 비정상적 레이블을 제거하고 학습을 정상적으로 진행했음에도 불구하고, 여전히 '중립' 클래스의 f1-score가 현저히 낮게 측정되는 별개의 문제(데이터 불균형으로 추정)
- **2차 구현(개선)**
    빠른 프로토타이핑을 위한 Scikit-learn(로지스틱 회귀) 모델과, 더 높은 성능을 기대할 수 있는 Deep Learning(LSTM) 모델 두 가지를 모두 학습하고 테스트할 수 있도록 UI와 로직을 분리
    class_weight='balanced'로 데이터가 적은 클래스에 자동으로 높은 가중치를 부여
    학습 속도가 빠른 Scikit-learn의 이점을 활용하여 '텍스트 직접 입력 테스트'에서 모델이 틀린 예측을 하면, 사용자가 올바른 레이블을 달아 피드백을 주는 기능을 추가
    약 3만개의 추가 데이터(총 5만 이상)로 모델 학습 이후 추가 피드백 진행(테스트 시 예측률이 낮거나 틀린 리뷰)

### 4. 시각화
- **1차 구현**
  감성 분포도와   리뷰 텍스트에서 감성별 단어 총 등장 횟수를 기반으로 워드클라우드를 생성.
- **시행착오**  
  한명의 유저가 같은 문장을 반복적으로 쓴 리뷰가 있는 경우 그 단어가 워드클라우드를 지배하는 문제
  '게임', '플레이' 등 모든 감성에서 공통적으로 나타나는 단어들이 상위권에 나타나는 문제
  다양한 운영체제에서 한글이 깨지는 문제
- **2차 구현(개선)**  
  단어 빈도 집계 시, 각 리뷰 내에서 고유한 단어만 추출하여 특정 리뷰의 과도한 영향력을 차단
  기본, 게임별, 임시 세개의 불용어 리스트를 만들고 통합하여 적용
  platform 모듈로 OS를 감지하여 Windows, macOS, Linux 환경에 맞는 기본 한글 폰트 경로를 자동으로 찾아 설정하도록 개선
  
## 🚀 향후 프로젝트 계획: 기준별 감성 분석 서비스

- 현재의 감성 분석 대시보드를 기반으로, 사용자가 원하는 **평가 기준(키워드)**에 따라 게임의 장단점을 명확하게 파악할 수 있는 **기준별 감성 분석 서비스**로 확장하는 것을 목표로 합니다.

### 1. 기본 모델 제공 및 지속적인 개선

-   **기본 모델 탑재**: 이 프로젝트에서 학습시킨 가장 성능이 우수한 모델을 서비스의 **기본 모델(Baseline Model)**로 탑재하여, 별도의 학습 과정 없이도 즉시 감성 분석을 이용할 수 있도록 제공합니다.
-   **사용자 피드백 반영**: 사용자는 '실시간 판별' 기능의 피드백 루프를 통해 자신의 데이터나 특정 게임의 리뷰에 맞게 모델을 **지속적으로 개선하고 개인화**할 수 있습니다.

### 2. 기준별 감성 리뷰 필터링 및 시각화 (신규 핵심 기능)

- 사용자가 특정 키워드(예: '그래픽', '스토리', '최적화')를 입력하면, 해당 키워드가 포함된 리뷰들만 필터링하여 감성 분석을 수행하고, 그 결과를 집계하여 시각화합니다.

    *   **키워드 기반 필터링**: 전체 리뷰 중에서 사용자가 입력한 키워드를 포함하는 리뷰들만 선별합니다.

    *   **기준별 감성 분석 및 시각화**: 선별된 리뷰들에 대해 학습된 모델로 감성 분석을 수행하고, 최종적으로 해당 기준에 대한 긍정, 중립, 부정 리뷰의 개수를 막대그래프나 표 등으로 명확하게 보여줍니다.

        > **(예시)**
        > 사용자가 '그래픽'이라는 키워드를 입력하면,
        > 1. '그래픽'이 언급된 모든 리뷰를 찾습니다.
        > 2. 찾아낸 리뷰들을 하나씩 감성 분석합니다.
        > 3. 최종 결과를 집계하여 보여줍니다.
        >    -   그래픽 (긍정 ✅): 120개
        >    -   그래픽 (중립 ⏸️): 15개
        >    -   그래픽 (부정 ❌): 8개

### 3. 기대 효과

-   **게이머**: "이 게임은 그래픽에 대한 긍정적 평가가 많은가?", "스토리에 대한 평가는 어떤가?"와 같이, 자신이 중요하게 생각하는 특정 요소에 대한 여론을 구매 전에 객관적인 수치로 확인할 수 있습니다.
-   **게임 개발사**: 유저들이 어떤 부분(그래픽, 버그, 스토리 등)에 대해 긍정 또는 부정적인 의견을 많이 남기는지 정량적으로 파악하여, 마케팅 전략을 수립하거나 업데이트 우선순위를 정하는 데 활용할 수 있습니다.
