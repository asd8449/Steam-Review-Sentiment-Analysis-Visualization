import streamlit as st
import pandas as pd
from myLangchainService import LLMSentimentAnalyzer, load_corpus_from_csv
import os

st.set_page_config(page_title="LLM ë ˆì´ë¸”ë§", page_icon="ğŸ¤–")
st.title("ğŸ¤– LLM ê¸°ë°˜ ê°ì„± ë ˆì´ë¸”ë§")
st.markdown("`data` í´ë”ì— ìˆëŠ” ì›ë³¸ ë¦¬ë·° íŒŒì¼(.csv)ì„ ì„ íƒí•˜ì—¬ LLMìœ¼ë¡œ ê°ì„± ë ˆì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤. **ì´ ê³¼ì •ì—ì„œ 'Posted:', 'EARLY ACCESS REVIEW' ë“±ì˜ ì ‘ë‘ì‚¬ê°€ ìë™ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤.**")
data_dir = 'data'
if not os.path.exists(data_dir): os.makedirs(data_dir)
source_files = [f for f in os.listdir(data_dir) if f.startswith('steam_reviews_') and f.endswith('.csv')]
if not source_files:
    st.warning("ë¨¼ì € 'ë°ì´í„° ìˆ˜ì§‘' ë©”ë‰´ì—ì„œ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
    st.stop()

selected_file = st.selectbox("ë ˆì´ë¸”ë§í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", source_files)
df = None
default_col = 'review'
if selected_file:
    file_path = os.path.join(data_dir, selected_file)
    st.markdown("---")
    st.subheader("ğŸ“„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ì •ë³´")
    try:
        df = pd.read_csv(file_path)
        st.info(f"ì´ ë°ì´í„° ê°œìˆ˜: **{len(df)}**ê°œ")
        st.write("**ë°ì´í„° ìƒìœ„ 5ê°œ í–‰:**")
        st.dataframe(df.head())
        st.write("**ì»¬ëŸ¼ ëª©ë¡:**"); st.code(', '.join(df.columns))
        if 'review' in df.columns: default_col = 'review'
        elif 'document' in df.columns: default_col = 'document'
        elif df.columns.any(): default_col = df.columns[0]
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

st.markdown("---")
st.subheader("âš™ï¸ ë ˆì´ë¸”ë§ ì„¤ì • ë° ì‹œì‘")
if df is not None:
    with st.form('llm_labeling_form'):
        column_name = st.text_input('ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì»¬ëŸ¼ëª…', value=default_col)
        start_index = st.number_input("ì‹œì‘ ì¸ë±ìŠ¤", 0, max_value=len(df)-1, key="start_idx")
        num_to_label = st.number_input("ë ˆì´ë¸”ë§í•  ë¬¸ì„œ ìˆ˜", value=100, min_value=1, key="num_label")
        st.write("### LLM ì„œë²„ ì„¤ì •")
        server_endpoint = st.text_input("LLM ì„œë²„ ì—”ë“œí¬ì¸íŠ¸", value="http://127.0.0.1:1234/v1")
        model_name = st.text_input("LLM ëª¨ë¸ëª…", value="google/gemma-3-12b")
        submitted = st.form_submit_button('ë ˆì´ë¸”ë§ ì‹œì‘', type="primary")
else:
    st.warning("íŒŒì¼ì„ ì„ íƒí•˜ê³  ë¯¸ë¦¬ë³´ê¸°ë¥¼ í™•ì¸í•œ í›„ ì„¤ì •ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")

def start_sentiment_labeling(corpus, result_container, status_placeholder, sa):
    labels = []
    for i, review_text in enumerate(corpus):
        if not isinstance(review_text, str) or not review_text.strip():
            labels.append("ì¤‘ë¦½"); result_container.write(f'[ì¤‘ë¦½] (ë‚´ìš© ì—†ìŒ)')
            continue
        response = sa.analyze_sentiment(review_text)
        result_container.write(f'[{response}] {review_text}')
        labels.append(response)
        status_placeholder.info(f'ğŸ”„ ì§„í–‰ ì¤‘: {i+1} / {len(corpus)}ê°œ ë¬¸ì„œ ë ˆì´ë¸”ë§ ì™„ë£Œ...')
    return labels

if 'submitted' in locals() and submitted:
    status = st.empty()
    status.info('ë°ì´í„° ë¡œë”© ë° ì •ì œ ì¤‘...')
    corpus = load_corpus_from_csv(file_path, column_name)
    if corpus is None:
        st.error(f"ì»¬ëŸ¼ '{column_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    if start_index + num_to_label > len(corpus):
        st.warning(f"ìš”ì²­ ë²”ìœ„ê°€ ë°ì´í„° í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ì—¬ ê°€ëŠ¥í•œ ë²”ìœ„ê¹Œì§€ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
        num_to_label = len(corpus) - start_index
    end_index = start_index + num_to_label
    corpus_subset = corpus[start_index:end_index]
    st.info(f"ì •ì œëœ í…ìŠ¤íŠ¸ ì´ {len(corpus)}ê°œ ì¤‘ {start_index}ë²ˆë¶€í„° {end_index-1}ë²ˆê¹Œì§€, ì´ {len(corpus_subset)}ê°œ ë ˆì´ë¸”ë§ ì‹œì‘.")
    result_box = st.container(height=400, border=True)
    try:
        sa = LLMSentimentAnalyzer(server_endpoint, model_name)
        label_list = start_sentiment_labeling(corpus_subset, result_box, status, sa)
        status.success('âœ… ë ˆì´ë¸”ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.')
        original_df = pd.read_csv(file_path).iloc[start_index:end_index]
        labeled_df = pd.DataFrame({'document': corpus_subset, 'label': label_list})
        if 'rating' in original_df.columns:
            labeled_df['rating'] = original_df['rating'].values
            labeled_df = labeled_df[['document', 'rating', 'label']]
        output_filename = f"labeled_{os.path.basename(file_path)}"
        output_path = os.path.join(data_dir, output_filename)
        labeled_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        st.success(f"'{output_path}'ì— ì €ì¥ ì™„ë£Œ!"); st.dataframe(labeled_df)
    except Exception as e:
        st.error(f"LLM API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); st.warning("LLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")